{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexile Score Range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grade Level</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Grade 2 - Grade 4</th>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grade &lt; 2</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grade &gt; 4</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Lexile Score Range\n",
       "Grade Level                          \n",
       "Grade 2 - Grade 4                 456\n",
       "Grade < 2                          62\n",
       "Grade > 4                          30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_excel(\"dataset_modelling.xlsx\")\n",
    "\n",
    "#map lexile score to grade level(Ordinal Variables)\n",
    "#https://www.scholastic.com/parents/books-and-reading/reading-resources/book-selection-tips/lexile-levels-made-easy.html\n",
    "map_dict={'BR190L - 0L':'Grade < 2',\n",
    "'10L - 200L':'Grade < 2',\n",
    "'210L - 400L':'Grade < 2',\n",
    "'410L - 600L':'Grade 2 - Grade 4',\n",
    "'610L - 800L':'Grade 2 - Grade 4',\n",
    "'810L - 1000L':'Grade 2 - Grade 4',\n",
    "'1010L - 1200L':'Grade > 4',\n",
    "'1210L - 1400L':'Grade > 4'}\n",
    "\n",
    "data[\"Grade Level\"]=data[\"Lexile Score Range\"].map(map_dict)\n",
    "data[[\"Lexile Score Range\",\"Grade Level\"]].groupby([\"Grade Level\"]).count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting grade level to ordinal variable for using as the target variable in modelling\n",
    "map_dict_ordinal={'Grade < 2':1,\n",
    "'Grade 2 - Grade 4':2,\n",
    "'Grade > 4':3}\n",
    "\n",
    "data[\"Lexile Score Range - Label\"]=data[\"Grade Level\"].map(map_dict_ordinal).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Baseline Model\n",
      "Accuracy:  88.5 %\n"
     ]
    }
   ],
   "source": [
    "#Baseline Model\n",
    "\n",
    "X=data[['Word_Count', 'Sentence_Count', 'Avg_Word_Length', 'Avg_No_Word_Per_Sentence', 'Avg_Syllable_Count_Per_Word', 'No_Complex_Words', 'No_Common_Words', 'Avg_No_Complex_Words_Per_Sentence', 'Avg_No_Simple_Words_Per_Sentence', 'Ratio_Complex_Words_Per_Common_Words', 'No_Easy_Words', 'No_Difficulty_Words', 'Avg_No_Easy_Words_Per_Sentence', 'Avg_No_Difficulty_Words_Per_Sentence', 'Ratio_Difficulty_Words_Per_Easy_Words', 'Automated_Readability_Index', 'Flesch_Reading_Ease', 'FleschKincaid_Grade_Level', 'Coleman_Liau_Index', 'Gunning_Fog_Index', 'SMOG_Index', 'Linsear_Write', 'Dale_Chall_Readability', 'ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'CONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SPACE', 'SYM', 'VERB', 'X']]\n",
    "y=data[\"Lexile Score Range - Label\"]\n",
    "\n",
    "randomforestmodel=RandomForestClassifier(n_estimators=1000,random_state=42)\n",
    "\n",
    "#Baseline Model\n",
    "print(\"Random Forest: Baseline Model\")\n",
    "scores = cross_val_score(randomforestmodel, X, y, cv=4, scoring='accuracy')\n",
    "print(\"Accuracy: \",round((scores.mean())*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (383, 42)\n",
      "Training Labels Shape: (165, 42)\n",
      "\n",
      "\n",
      "Base Model: Random Forest\n",
      "No of features Selected:  16\n",
      "Selected Features:  Index(['Word_Count', 'Avg_Word_Length', 'No_Common_Words',\n",
      "       'Avg_No_Complex_Words_Per_Sentence', 'No_Easy_Words',\n",
      "       'Avg_No_Difficulty_Words_Per_Sentence', 'Automated_Readability_Index',\n",
      "       'Flesch_Reading_Ease', 'FleschKincaid_Grade_Level',\n",
      "       'Coleman_Liau_Index', 'Gunning_Fog_Index', 'SMOG_Index', 'ADP', 'CCONJ',\n",
      "       'DET', 'NOUN'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Feature Selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=42,shuffle=True)\n",
    "\n",
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', X_test.shape)\n",
    "\n",
    "print('\\n')\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 1000, random_state=42))\n",
    "sel.fit(X_train, y_train)\n",
    "\n",
    "print(\"Base Model: Random Forest\" )\n",
    "selected_features= X_train.columns[(sel.get_support())]\n",
    "print(\"No of features Selected: \",len(selected_features))\n",
    "print(\"Selected Features: \",selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 - Random Forest: Baseline Model with Selected Features\n",
      "Accuracy:  88.5 %\n"
     ]
    }
   ],
   "source": [
    "#Baseline model with selected features\n",
    "X=data[selected_features]\n",
    "randomforestmodel=RandomForestClassifier(n_estimators=1000,random_state=42)\n",
    "#Baseline Model\n",
    "print(\"Model 1 - Random Forest: Baseline Model with Selected Features\")\n",
    "scores = cross_val_score(randomforestmodel, X, y, cv=4, scoring='accuracy')\n",
    "print(\"Accuracy: \",round((scores.mean())*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   24.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 600, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 4, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "#Random Forest - RandomizedSearch with Parameter Tuning\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [4, 8, 12, 16],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [200, 400, 600, 800,1000]\n",
    "}\n",
    "\n",
    "randomforestmodel=RandomForestClassifier(n_estimators=1000,random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = randomforestmodel, param_distributions=param_grid, cv = 4, n_jobs = -1, verbose = 2)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2- Random Forest Tuned Model with Selected Features\n",
      "Accuracy:  89.42 %\n"
     ]
    }
   ],
   "source": [
    "#Random Forest - RandomizedSearch with Parameter Tuned Model\n",
    "\n",
    "randomforestmodel=RandomForestClassifier(n_estimators=600,\n",
    "                       random_state=42,\n",
    "                       min_samples_split=12,\n",
    "                       min_samples_leaf=4,\n",
    "                       max_features='sqrt',\n",
    "                       max_depth=4,\n",
    "                       bootstrap=False)\n",
    "\n",
    "print(\"Model 2- Random Forest Tuned Model with Selected Features\")\n",
    "scores = cross_val_score(randomforestmodel, X, y, cv=4, scoring='accuracy')\n",
    "print(\"Accuracy: \",round((scores.mean())*100,2),\"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3- Support Vector Machine\n",
      "Accuracy:  83.21 %\n"
     ]
    }
   ],
   "source": [
    "#SVC Classifier\n",
    "X=data[['Word_Count', 'Sentence_Count', 'Avg_Word_Length', 'Avg_No_Word_Per_Sentence', 'Avg_Syllable_Count_Per_Word', 'No_Complex_Words', 'No_Common_Words', 'Avg_No_Complex_Words_Per_Sentence', 'Avg_No_Simple_Words_Per_Sentence', 'Ratio_Complex_Words_Per_Common_Words', 'No_Easy_Words', 'No_Difficulty_Words', 'Avg_No_Easy_Words_Per_Sentence', 'Avg_No_Difficulty_Words_Per_Sentence', 'Ratio_Difficulty_Words_Per_Easy_Words', 'Automated_Readability_Index', 'Flesch_Reading_Ease', 'FleschKincaid_Grade_Level', 'Coleman_Liau_Index', 'Gunning_Fog_Index', 'SMOG_Index', 'Linsear_Write', 'Dale_Chall_Readability', 'ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'CONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SPACE', 'SYM', 'VERB', 'X']]\n",
    "y=data[\"Lexile Score Range - Label\"]\n",
    "\n",
    "\n",
    "svcmodel=SVC(C=1.0,random_state=42)\n",
    "#SVC baseline model\n",
    "print(\"Model 3- Support Vector Machine\")\n",
    "scores = cross_val_score(svcmodel, X, y, cv=4, scoring='accuracy')\n",
    "print(\"Accuracy: \",round((scores.mean())*100,2),\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 - XGBoost BaseLine Model\n",
      "Accuracy:  87.96 %\n"
     ]
    }
   ],
   "source": [
    "#Xgboost Classifer\n",
    "\n",
    "X=data[['Word_Count', 'Sentence_Count', 'Avg_Word_Length', 'Avg_No_Word_Per_Sentence', 'Avg_Syllable_Count_Per_Word', 'No_Complex_Words', 'No_Common_Words', 'Avg_No_Complex_Words_Per_Sentence', 'Avg_No_Simple_Words_Per_Sentence', 'Ratio_Complex_Words_Per_Common_Words', 'No_Easy_Words', 'No_Difficulty_Words', 'Avg_No_Easy_Words_Per_Sentence', 'Avg_No_Difficulty_Words_Per_Sentence', 'Ratio_Difficulty_Words_Per_Easy_Words', 'Automated_Readability_Index', 'Flesch_Reading_Ease', 'FleschKincaid_Grade_Level', 'Coleman_Liau_Index', 'Gunning_Fog_Index', 'SMOG_Index', 'Linsear_Write', 'Dale_Chall_Readability', 'ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'CONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SPACE', 'SYM', 'VERB', 'X']]\n",
    "y=data[\"Lexile Score Range - Label\"]\n",
    "\n",
    "xgbmodel=xgb.XGBClassifier(objective='multi:softprob',random_state=42)\n",
    "#XGB baseline model\n",
    "print(\"Model 4 - XGBoost BaseLine Model\")\n",
    "scores = cross_val_score(xgbmodel, X, y, cv=4, scoring='accuracy')\n",
    "print(\"Accuracy: \",round((scores.mean())*100,2),\"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (383, 42)\n",
      "Training Labels Shape: (165, 42)\n",
      "No of features Selected:  11\n",
      "Selected Features:  Index(['Word_Count', 'Avg_Word_Length', 'Avg_No_Complex_Words_Per_Sentence',\n",
      "       'No_Difficulty_Words', 'Automated_Readability_Index',\n",
      "       'FleschKincaid_Grade_Level', 'Coleman_Liau_Index', 'NOUN', 'NUM',\n",
      "       'PRON', 'SCONJ'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Feature Selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=42,shuffle=True)\n",
    "\n",
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', X_test.shape)\n",
    "\n",
    "sel = SelectFromModel(xgb.XGBClassifier(objective='multi:softprob',random_state=42))\n",
    "sel.fit(X_train, y_train)\n",
    "\n",
    "selected_features= X_train.columns[(sel.get_support())]\n",
    "print(\"No of features Selected: \",len(selected_features))\n",
    "print(\"Selected Features: \",selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5 - XGBoost BaseLine Model with Selected Features\n",
      "Accuracy:  88.69 %\n"
     ]
    }
   ],
   "source": [
    "#XGBoost Baseline model with selected features\n",
    "X=data[selected_features]\n",
    "\n",
    "xgbmodel=xgb.XGBClassifier(objective='multi:softprob',random_state=42)\n",
    "\n",
    "#XGB baseline model with selected features\n",
    "print(\"Model 5 - XGBoost BaseLine Model with Selected Features\")\n",
    "scores = cross_val_score(xgbmodel, X, y, cv=4, scoring='accuracy')\n",
    "print(\"Accuracy: \",round((scores.mean())*100,2),\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 6, 'max_depth': 4, 'learning_rate': 0.01, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    7.3s finished\n"
     ]
    }
   ],
   "source": [
    "#XGBOOST - RandomizedSearch with Parameter Tuning\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [4, 8, 12, 16],\n",
    "    'min_child_weight':[2,4,6,8],\n",
    "    'subsample': [0.4,0.6,0.8],\n",
    "    'colsample_bytree': [0.4,0.6,0.8],\n",
    "    'n_estimators': [200, 400, 600, 800,1000],\n",
    "    'learning_rate':[0.01,0.03,0.1,0.3]   \n",
    "}\n",
    "xgb_search = RandomizedSearchCV(estimator = xgbmodel, param_distributions=param_grid, cv = 4, n_jobs = -1, verbose = 2)\n",
    "xgb_search.fit(X, y)\n",
    "print(xgb_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6- XgBoost Tuned Model with Selected Features\n",
      "Accuracy:  89.78 %\n"
     ]
    }
   ],
   "source": [
    "xgbmodel=xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
    "              learning_rate=0.01, max_delta_step=0, max_depth=12,\n",
    "              min_child_weight=8, missing=None, n_estimators=200, n_jobs=1,\n",
    "              nthread=None, objective='multi:softprob', random_state=42,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=0.8, verbosity=1)\n",
    "print(\"Model 6- XgBoost Tuned Model with Selected Features\")\n",
    "scores = cross_val_score(xgbmodel, X, y, cv=4, scoring='accuracy')\n",
    "print(\"Accuracy: \",round((scores.mean())*100,2),\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
